# Linux系统IO原理

## 书籍推荐
《深入理解Linux内核》《深入理解计算机系统》

## 面试问题
epoll是怎么知道数据到达、可以通知用户读取的？  
这里面有一个中断的概念，调用了epoll_wait
补充pagecache的知识：  
内存分配的时候是大家在物理内存中共同使用一个kernel，然后是各个应用程序都打散，分布到内存的各个地方，因为他们并不是一口气被分配出来的，而是
用到哪一部分就分配哪一部分，程序以碎片的方式在物理空间里，但是虚拟地址中他自己是独占的。这里面就牵扯到一个问题：虚拟内存中线性地址连续的两段
地址，可能被映射到不同的物理地址，这需要一个MMU，程序里还要把映射表提供给MMU去换算这个映射的关系表。硬件的MMU所依赖的是page，一页在物理内存
中的大小是默认4kB，管理物理内存线性地址的时候，一堆4k的小格子，程序用谁了，找个空的4k小格子，把数据放进去，并映射上。但是，系统不会全量分配，
所以有时候会有缺页异常，类似于软中断，跑到内核里面，开始建立页的映射关系，把页补上，然后在漂移回来，染CPU继续执行指令。C的操作系统进程跑起来之后，
有这么几段：代码段、数据段、栈、堆，寄存器会指向这几个段的基地址，然后给出便宜就知道具体哪个位置了。先从硬盘把程序文件appW(binary)加载到内存，
这个时候也会触发page，读4k先放进来。假设文件有10个4k，但是可能先房间一个4k，随着访问的需要，再继续分配，按需分配。  

IO的依赖是pagecache，虽然C的direct IO能够跳过内核的pagecache，但是Java里面没有direct IO，两java的mmap也是用的pagecache
```
[root@localhost ~]# sysctl -a | grep dirty
vm.dirty_background_bytes = 0
vm.dirty_background_ratio = 10
vm.dirty_bytes = 0
vm.dirty_expire_centisecs = 3000
vm.dirty_ratio = 30
vm.dirty_writeback_centisecs = 500
```
`vim /etc/sysctl.conf`修改以上的参数：
`vm.dirty_background_ratio = 90` 改为90%。假设还有10G可用，缓存占到9G的时候，才会有内核完成由内存到磁盘的写的过程，3G的内存，我们向
内存写2个多G之后才会真正落地到磁盘，这个可能丢很多数据。这是后台线程  
`vm.dirty_ratio = 90` 前台线程。程序往内核写的时候分配页已经分配到90%了（比前面的后台ratio要设置的稍微高一点），假设程序疯狂的向内核写
数据，再疯狂的分配pagecache，以达到可用内存的90%，这时候就阻塞程序（上面的不会阻塞，程序继续写，会起一个后台线程向磁盘写，如果线程比程序写
的快，则内存不会爆满），这时候把脏页的数据写到磁盘上，再写的话两个都会触发LRU，把老的、没怎么用的页淘汰出去，保证新数据能写到内存里。说白了就是
程序先写内存后写硬盘，只不过是什么时候写的问题。这两个设置可以关联到Redis做持久化aof、mySQL调有的时候的bin log等，它们都是有三个级别可以调，
一个是每秒钟写一次、随内核、每操作写一次，就是因为不是立即保存，有可能丢很多。现在修改后台线程时间的维度，脏页能存多久（单位是百分之一秒），
多长时间就要做一次写回硬盘：
```
vm.dirty_expire_centisecs = 30000
vm.dirty_writeback_centisecs = 50000
```
目的是不让时间成为干扰. 改完了之后要执行`sysctl -p`执行更新生效就想看一直写的话，突然关机，能丢多少数据。写的时候分配的页，一开始申请过来
就是脏的，往内存里写过了就不是脏的了。不脏的页，可以背LRU或者LFU淘汰掉，如果是脏的页，那不能在内存中抹杀掉，是要先写到磁盘中才能淘汰掉。
现在(192.168.199上)执行：`/root/mysh` 试图往磁盘里写数据：
```
[root@localhost testfileio]# ll -h && pcstat out.txt
total 79M
-rwxr-xr-x. 1 root root  112 Nov  8 17:13 mysh
-rw-r--r--. 1 root root 4.0K Nov  8 17:39 OSFileIO.class
-rwxr-xr-x. 1 root root 4.5K Nov  8 17:39 OSFileIO.java
-rw-r--r--. 1 root root 9.5K Nov  8 17:39 out.71970
-rw-r--r--. 1 root root  52M Nov  8 17:40 out.71971
-rw-r--r--. 1 root root 4.0K Nov  8 17:40 out.71972
-rw-r--r--. 1 root root  928 Nov  8 17:39 out.71973
-rw-r--r--. 1 root root 1.1K Nov  8 17:39 out.71974
-rw-r--r--. 1 root root  972 Nov  8 17:39 out.71975
-rw-r--r--. 1 root root 6.7K Nov  8 17:40 out.71976
-rw-r--r--. 1 root root 4.6K Nov  8 17:40 out.71977
-rw-r--r--. 1 root root  928 Nov  8 17:39 out.71978
-rw-r--r--. 1 root root  45K Nov  8 17:40 out.71979
-rw-r--r--. 1 root root  12M Nov  8 17:40 out.txt
+---------+----------------+------------+-----------+---------+
| Name    | Size (bytes)   | Pages      | Cached    | Percent |
|---------+----------------+------------+-----------+---------|
| out.txt | 11951370       | 2918       | 2918      | 100.000 |
+---------+----------------+------------+-----------+---------+
```
只要内存够，pagecache就一直缓存。未来想读头的时候，不需要产生磁盘IO就可以读到。可以看到，似乎写了不上，虽然速度不是太快（sleep已经注释掉了，
减少了系统调用，没有用内切换）。但是现在直接"拔电源"，然后再次启动回来再查看pagecache的情况：
```
Shuzheng-Mac2:Documents shuzheng$ ssh root@192.168.1.99
Last login: Sun Nov  8 17:56:39 2020 from 192.168.1.102
[root@localhost ~]# cd testfileio/
[root@localhost testfileio]# ll -h
total 16K
-rwxr-xr-x. 1 root root  112 Nov  8 17:13 mysh
-rw-r--r--. 1 root root 4.0K Nov  8 18:08 OSFileIO.class
-rwxr-xr-x. 1 root root 4.5K Nov  8 17:39 OSFileIO.java
-rw-r--r--. 1 root root    0 Nov  8 18:08 out.2494
-rw-r--r--. 1 root root    0 Nov  8 18:09 out.2495
-rw-r--r--. 1 root root    0 Nov  8 18:09 out.2496
-rw-r--r--. 1 root root    0 Nov  8 18:08 out.2497
-rw-r--r--. 1 root root    0 Nov  8 18:08 out.2498
-rw-r--r--. 1 root root    0 Nov  8 18:08 out.2499
-rw-r--r--. 1 root root    0 Nov  8 18:09 out.2500
-rw-r--r--. 1 root root    0 Nov  8 18:09 out.2501
-rw-r--r--. 1 root root    0 Nov  8 18:08 out.2502
-rw-r--r--. 1 root root    0 Nov  8 18:09 out.2503
-rw-r--r--. 1 root root    0 Nov  8 18:09 out.txt
```
可见由于内核参数配置的太高了，OS并没有来得及保存到硬盘。
现在测试用`BufferedOutputStream` 来往磁盘里写，也就是在FileOutputStream外面套一层BufferedOutputStream，还是要注释掉sleep，不带flush()